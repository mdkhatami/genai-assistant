# üõ†Ô∏è GenAI Assistant - Developer Guide

This guide provides comprehensive information for developers working on the GenAI Assistant project, including project structure, development setup, testing, and contribution guidelines.

## üìã Table of Contents
- [Project Structure](#project-structure)
- [System Architecture](#system-architecture)
- [Development Setup](#development-setup)
- [API Reference](#api-reference)
- [Core Components](#core-components)
- [Testing](#testing)
- [Contributing](#contributing)

---

## üìÅ Project Structure

### FastAPI Application Structure
```
genai_assitant/
‚îú‚îÄ‚îÄ app/                          # Main FastAPI application package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI application entry point
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Pydantic models for API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py           # Request/Response models
‚îÇ   ‚îú‚îÄ‚îÄ auth/                    # Authentication module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.py             # JWT authentication
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Main configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_loader.py    # Configuration loader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ debug_config.py     # Debug configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py   # Logging configuration
‚îÇ   ‚îú‚îÄ‚îÄ cli/                     # Command-line interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cli.py              # CLI commands
‚îÇ   ‚îî‚îÄ‚îÄ core/                    # Core functionality
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ llm_response.py
‚îÇ       ‚îú‚îÄ‚îÄ optimized_image_generation.py
‚îÇ       ‚îî‚îÄ‚îÄ robust_transcription.py
‚îú‚îÄ‚îÄ docs/                        # Documentation
‚îú‚îÄ‚îÄ scripts/                     # Utility and test scripts
‚îú‚îÄ‚îÄ standalone_webapp/           # Standalone web application (frontend)
‚îú‚îÄ‚îÄ genai_ui/                    # React UI components (frontend)
‚îú‚îÄ‚îÄ main.py                      # Application entry point
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ start_server.sh              # Server startup script
‚îî‚îÄ‚îÄ setup_venv.sh                # Virtual environment setup
```

---

## üèõÔ∏è System Architecture

### High-Level Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        WEB[üåê Standalone WebApp]
        CLI[üíª CLI Interface]
        API_CLIENT[üîå API Clients]
    end
    
    subgraph "API Gateway"
        FASTAPI[‚ö° FastAPI Server]
        AUTH[üîê JWT Authentication]
        CORS[üåç CORS Middleware]
    end
    
    subgraph "Core Services"
        LLM_SERVICE[ü§ñ LLM Service]
        IMG_SERVICE[üé® Image Generation]
        TRANS_SERVICE[üé§ Transcription]
        FILE_SERVICE[üìÅ File Management]
    end
    
    subgraph "AI Providers"
        OPENAI[üß† OpenAI API]
        OLLAMA[ü¶ô Ollama Local]
        FLUX[üé≠ Flux Models]
        WHISPER[üëÇ Whisper Models]
    end
    
    subgraph "Infrastructure"
        GPU1[üéÆ GPU 1 - Ollama LLM]
        GPU2[üéÆ GPU 2 - Transcription]
        GPU3[üéÆ GPU 3 - Image Generation]
        STORAGE[üíæ File Storage]
    end
    
    WEB --> FASTAPI
    CLI --> FASTAPI
    API_CLIENT --> FASTAPI
    
    FASTAPI --> AUTH
    FASTAPI --> CORS
    
    AUTH --> LLM_SERVICE
    AUTH --> IMG_SERVICE
    AUTH --> TRANS_SERVICE
    AUTH --> FILE_SERVICE
    
    LLM_SERVICE --> OPENAI
    LLM_SERVICE --> OLLAMA
    IMG_SERVICE --> FLUX
    TRANS_SERVICE --> WHISPER
    
    OLLAMA --> GPU1
    WHISPER --> GPU2
    FLUX --> GPU3
    
    FILE_SERVICE --> STORAGE
    IMG_SERVICE --> STORAGE
    TRANS_SERVICE --> STORAGE
```

### Key Components

#### 1. FastAPI Application (`app/main.py`)
- **Purpose**: Main FastAPI application with all endpoints
- **Features**: CORS middleware, authentication, static file serving
- **Endpoints**: LLM, image generation, transcription, authentication

#### 2. Models (`app/models/`)
- **Purpose**: Pydantic models for request/response validation
- **Files**: `models.py` - All API request/response models
- **Usage**: Type safety and automatic validation

#### 3. Authentication (`app/auth/`)
- **Purpose**: JWT-based authentication system
- **Features**: User authentication, token generation, middleware
- **Security**: Password hashing with bcrypt

#### 4. Configuration (`app/config/`)
- **Purpose**: Centralized configuration management
- **Files**:
  - `config.py` - Main configuration classes
  - `config_loader.py` - Configuration loading and validation
  - `debug_config.py` - Debug configuration utilities
  - `logging_config.py` - Logging setup and configuration

#### 5. CLI (`app/cli/`)
- **Purpose**: Command-line interface for all functionalities
- **Features**: LLM, image generation, transcription commands
- **Usage**: `python -m app.cli.cli <command>`

#### 6. Core (`app/core/`)
- **Purpose**: Core AI functionality implementation
- **Modules**:
  - `llm_response.py` - OpenAI and Ollama LLM integration
  - `optimized_image_generation.py` - Image generation with Flux models
  - `robust_transcription.py` - Audio transcription with Whisper

---

## üõ†Ô∏è Development Setup

### 1. Environment Setup
```bash
# Clone the repository
git clone <repository-url>
cd genai_assitant

# Create virtual environment
./setup_venv.sh

# Activate virtual environment
source venv/bin/activate
```

### 2. Configuration
```bash
# Copy environment template
cp .env_example .env

# Edit .env with your configuration
nano .env
```

### 3. Install Dependencies
```bash
# Install Python dependencies
pip install -r requirements.txt

# Install development dependencies (if any)
pip install -r requirements-dev.txt
```

### 4. Development Server
```bash
# Start development server
./start_development.sh

# Or manually
# Port is configurable via WEB_PORT in .env (default: 5000)
uvicorn app.main:app --host 0.0.0.0 --port ${WEB_PORT:-5000} --reload
```

---

## üîß API Reference

### Authentication Endpoints

#### Login
```http
POST /auth/login
Content-Type: application/json

{
  "username": "admin",
  "password": "admin123"
}
```

**Response**:
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer",
  "username": "admin"
}
```

### Health & Info Endpoints

#### Get System Health
```http
GET /health
```

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2025-08-14T20:33:33.001906",
  "version": "1.0.0",
  "components": {
    "openai_llm": "healthy",
    "ollama_llm": "healthy", 
    "image_generator": "healthy",
    "transcriber": "healthy"
  }
}
```

### LLM Endpoints

#### OpenAI LLM
```http
POST /api/llm/openai
Authorization: Bearer <token>
Content-Type: application/json

{
  "prompt": "What is artificial intelligence?",
  "model": "gpt-4",
  "max_tokens": 1000,
  "temperature": 0.7,
  "system_message": "You are a helpful assistant."
}
```

#### Ollama LLM
```http
POST /api/llm/ollama
Authorization: Bearer <token>
Content-Type: application/json

{
  "prompt": "Explain quantum computing",
  "model": "llama2",
  "max_tokens": 1000,
  "temperature": 0.7,
  "system_message": "You are a helpful assistant."
}
```

#### Get Ollama Models
```http
GET /api/llm/ollama/models
Authorization: Bearer <token>
```

**Response**:
```json
{
  "success": true,
  "models": [
    {
      "name": "llama2",
      "size": 3790000000,
      "modified_at": "2025-08-14T20:00:00Z"
    }
  ],
  "total_models": 1,
  "server_url": "http://localhost:${OLLAMA_PORT:-11434}",  # Configurable via OLLAMA_PORT in .env
  "server_status": "running",
  "server_version": "0.1.0"
}
```

### Image Generation Endpoints

#### Generate Images
```http
POST /api/image/generate
Authorization: Bearer <token>
Content-Type: application/json

{
  "prompt": "A beautiful sunset over mountains",
  "model": "flux-dev",
  "resolution": "1024x1024",
  "count": 1,
  "steps": 20,
  "guidance_scale": 3.5
}
```

#### Get Available Models
```http
GET /api/image/models
Authorization: Bearer <token>
```

### Transcription Endpoints

#### Transcribe Audio
```http
POST /api/transcribe
Authorization: Bearer <token>
Content-Type: multipart/form-data

file: <audio_file>
model_name: "base"
language: "en"
task: "transcribe"
device: "cuda"
gpu_index: 2
```

#### Get Transcription Models
```http
GET /api/transcribe/models
Authorization: Bearer <token>
```

#### Get Transcription Info
```http
GET /api/transcribe/info
Authorization: Bearer <token>
```

### File Access Endpoints

#### Access Generated Files
```http
GET /generated/{filename}
```

#### Access Uploaded Files
```http
GET /uploads/{filename}
```

---

## üîß Core Components

### LLM Service
**Purpose**: Large Language Model integration and management

**Components**:
- **OpenAI Integration**: GPT-4, GPT-3.5-turbo, GPT-4-turbo
- **Ollama Integration**: Local models (llama3.3, qwen3, mistral, etc.)
- **Model Management**: Dynamic model loading and caching
- **Response Processing**: Structured response formatting

**Key Features**:
- ‚úÖ Multi-provider support (OpenAI + Ollama)
- ‚úÖ Model selection and configuration
- ‚úÖ Streaming support
- ‚úÖ Function calling capabilities
- ‚úÖ Comprehensive error handling
- ‚úÖ Request logging and monitoring

### Image Generation Service
**Purpose**: AI-powered image generation using Flux models

**Components**:
- **Flux Model Integration**: flux-dev, flux, flux-dev-8bit, flux-dev-4bit
- **GPU Optimization**: Multi-GPU support with GPU 3 allocation
- **Batch Processing**: Multiple image generation (1-8 images)
- **Parameter Control**: Resolution, steps, guidance scale

**Key Features**:
- ‚úÖ Multiple Flux model variants
- ‚úÖ Configurable resolution (512x512 to 1024x1024)
- ‚úÖ Batch image generation
- ‚úÖ GPU memory optimization
- ‚úÖ Base64 response format
- ‚úÖ Metadata tracking

### Transcription Service
**Purpose**: Audio/video transcription using Whisper models

**Components**:
- **Faster-Whisper**: Optimized local transcription
- **OpenAI Whisper**: Cloud-based transcription
- **Language Detection**: Auto-detection and manual selection
- **Advanced Parameters**: Beam size, temperature, VAD filtering

**Key Features**:
- ‚úÖ Dual Whisper implementations
- ‚úÖ Multiple model sizes (tiny to large-v3)
- ‚úÖ Language auto-detection
- ‚úÖ GPU acceleration (GPU 2)
- ‚úÖ Advanced parameter control
- ‚úÖ Word-level timestamps
- ‚úÖ VAD (Voice Activity Detection)

### File Management Service
**Purpose**: File upload, storage, and retrieval

**Components**:
- **Upload Handling**: Audio/video file processing
- **Storage Management**: Organized file storage
- **Access Control**: Secure file access
- **Metadata Tracking**: File information and processing status

**Key Features**:
- ‚úÖ Multi-format support (MP3, WAV, M4A, OGG, FLAC)
- ‚úÖ File size limits (16MB max)
- ‚úÖ Secure file access
- ‚úÖ Generated file management
- ‚úÖ Upload progress tracking

---

## üß™ Testing

### Test Structure
```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ test_image_generation.py
‚îú‚îÄ‚îÄ test_llm_response.py
‚îî‚îÄ‚îÄ test_transcription.py
```

### Running Tests
```bash
# Run all tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_llm_response.py

# Run with coverage
python -m pytest tests/ --cov=app

# Run integration tests
python scripts/test_llm_complete.py
python scripts/test_all_image_models.py
python scripts/final_transcription_test.py
```

### Test Scripts
```bash
# Test LLM functionality
python scripts/test_llm_complete.py

# Test image generation
python scripts/test_all_image_models.py

# Test transcription
python scripts/final_transcription_test.py

# Test server integration
python scripts/test_llm_with_server.py

# Test multi-GPU configuration
python scripts/test_multi_gpu_config.py
```

### Test Results
After restructuring, all core functionality is working:
- ‚úÖ **LLM**: OpenAI and Ollama working perfectly
- ‚úÖ **Server**: FastAPI server starts and runs correctly
- ‚úÖ **Authentication**: JWT authentication working
- ‚úÖ **API**: All endpoints functional
- ‚ö†Ô∏è **GPU Issues**: Some GPU-related issues (cuDNN, memory) are pre-existing

---

## üîí Security

### Authentication
- **JWT Tokens**: Secure token-based authentication
- **Password Hashing**: bcrypt for secure password storage
- **Token Expiration**: Configurable token lifetime
- **Session Management**: Secure session handling

### API Security
- **CORS Configuration**: Cross-origin request handling
- **Input Validation**: Pydantic models for request validation
- **Error Handling**: Secure error messages without information leakage
- **File Upload Security**: File type and size validation
- **Rate Limiting**: Consider implementing for production

### Data Protection
- **No Hardcoded Credentials**: Environment variable configuration
- **Secure Storage**: Encrypted credential storage
- **File Access Control**: Secure file serving
- **API Security**: Bearer token authentication

---

## üìä Performance & Scalability

### GPU Optimization
- **Multi-GPU Setup**: Dedicated GPUs for different services
- **Memory Management**: Efficient GPU memory usage
- **Model Caching**: Persistent model loading
- **Batch Processing**: Optimized batch operations

### Performance Metrics
- **Response Times**: Sub-second for most operations
- **Throughput**: Concurrent request handling
- **Memory Usage**: Optimized memory allocation
- **GPU Utilization**: Efficient GPU resource usage

### Scalability Considerations
- **Horizontal Scaling**: Multiple server instances
- **Load Balancing**: Nginx load balancing
- **Database Integration**: Future database support
- **Caching**: Redis caching for improved performance
- **CDN Integration**: Static file delivery optimization

---

## üìà Monitoring & Logging

### System Monitoring
- **Health Checks**: Automated system health monitoring
- **Performance Metrics**: Response time and throughput tracking
- **Error Tracking**: Comprehensive error logging
- **Resource Usage**: CPU, memory, and GPU monitoring

### Logging System
- **Structured Logging**: JSON-formatted logs
- **Log Rotation**: Automatic log file rotation
- **Log Levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL
- **Request Tracking**: Complete request/response logging

---

## ü§ù Contributing

### Development Workflow
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

### Code Standards
- **Python**: Follow PEP 8 style guide
- **FastAPI**: Use FastAPI best practices
- **Type Hints**: Use type hints for all functions
- **Documentation**: Update documentation for new features
- **Testing**: Write tests for new functionality

### Adding New Features
1. Add the endpoint in `app/main.py`
2. Create/update models in `app/models/models.py`
3. Add tests in `scripts/` directory
4. Update documentation

### Adding New Core Functionality
1. Add the module in `app/core/`
2. Update `app/core/__init__.py` exports
3. Add CLI commands in `app/cli/cli.py`
4. Add tests and documentation

### Configuration Changes
1. Update `app/config/config.py` for new settings
2. Update `app/config/config_loader.py` if needed
3. Update `.env_example` in the project root
4. Update documentation

---

## üìö Additional Resources

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **Pydantic Documentation**: https://pydantic-docs.helpmanual.io/
- **Uvicorn Documentation**: https://www.uvicorn.org/
- **OpenAI API Documentation**: https://platform.openai.com/docs
- **Ollama Documentation**: https://ollama.ai/docs

---

**Last Updated**: 2025-01-14  
**Version**: 1.0.0  
**Status**: ‚úÖ Production Ready