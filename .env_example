# GenAI Assistant Environment Configuration
# Copy this file to .env and fill in your actual values
# DO NOT commit the .env file to version control

# =============================================================================
# Authentication & Security
# =============================================================================

# JWT Configuration
# Generate a secure secret key with: openssl rand -hex 32
JWT_SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Admin User Configuration
# IMPORTANT: Change these default credentials in production!
ADMIN_USERNAME=admin
ADMIN_PASSWORD=change-this-password-in-production
ADMIN_EMAIL=admin@example.com
ADMIN_FULL_NAME=Administrator

# =============================================================================
# API Keys (Required for respective features)
# =============================================================================

# OpenAI API Key (required for OpenAI LLM features)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Hugging Face Token (required for image generation)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=your_huggingface_token_here

# =============================================================================
# Server Configuration
# =============================================================================

# Server host and port
HOST=0.0.0.0
PORT=5000
DEBUG=false
LOG_LEVEL=INFO

# CORS Configuration
# Comma-separated list of allowed origins for CORS
# For production, specify exact origins (e.g., "https://yourdomain.com,https://app.yourdomain.com")
# For development, defaults to localhost origins
CORS_ORIGINS=http://localhost:8080,http://localhost:3000,http://127.0.0.1:8080,http://127.0.0.1:3000

# =============================================================================
# Port Configuration
# =============================================================================
# All port numbers should be configured here - no hardcoded ports in the codebase

# Main FastAPI server port
WEB_PORT=5000

# Standalone webapp HTTP server port
WEBAPP_PORT=8080

# Ollama service port
OLLAMA_PORT=11434

# Nginx ports (for production deployment)
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# =============================================================================
# Device Configuration (GPU/CPU)
# =============================================================================

# Device Preference: "auto" (default), "gpu"/"cuda", or "cpu"
# - auto: Automatically detect and use GPU if available, fall back to CPU
# - gpu/cuda: Prefer GPU, warn if unavailable
# - cpu: Force CPU mode
DEVICE_PREFERENCE=auto

# Optional: Restrict which GPUs are visible to the application
# Only set this if you want to limit GPU visibility (e.g., multi-tenant systems)
# Leave commented out to use all available GPUs
# CUDA_VISIBLE_DEVICES=0,1,2,3

# GPU Index Configuration
# Specify which GPU to use for each service (optional)
# These override the global DEVICE_PREFERENCE for individual services
# Leave commented out to use DEVICE_PREFERENCE for all services
# OLLAMA_GPU_INDEX=1
# TRANSCRIPTION_GPU_INDEX=2
# IMAGE_GENERATION_GPU_INDEX=3

# =============================================================================
# Image Generation Configuration (Memory-Optimized)
# =============================================================================

# Image Generation Model Selection
# - flux-schnell: ~2GB VRAM (recommended for limited GPU memory, default)
# - flux-dev: ~12GB VRAM (requires significant GPU memory)
# CPU offload is automatically enabled for schnell model when GPU memory < 8GB
# IMAGE_GENERATION_MODEL=flux-schnell

# Image Generation Device
# "auto" (default), "gpu"/"cuda", or "cpu"
# IMAGE_GENERATION_DEVICE=auto

# Force CPU Offload for Image Generation
# Set to "true" to force CPU offload even when GPU memory is available
# This is useful for systems with limited GPU memory
# IMAGE_GENERATION_FORCE_CPU_OFFLOAD=false

# Image Generation Dimensions (default: 512x512 for schnell)
# IMAGE_GENERATION_WIDTH=512
# IMAGE_GENERATION_HEIGHT=512

# Image Generation Steps (default: 4 for schnell, optimal)
# IMAGE_GENERATION_STEPS=4

# Image Generation Guidance Scale (default: 0.0 for schnell, optimal)
# IMAGE_GENERATION_GUIDANCE_SCALE=0.0

# =============================================================================
# Ollama Configuration
# =============================================================================

# Ollama base URL
# OLLAMA_BASE_URL can be set directly, or will be constructed from OLLAMA_PORT
# If OLLAMA_BASE_URL is not set, it defaults to http://localhost:${OLLAMA_PORT}
OLLAMA_BASE_URL=http://localhost:11434
